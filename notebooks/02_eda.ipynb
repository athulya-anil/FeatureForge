{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - Criteo CTR Dataset\n",
    "\n",
    "This notebook performs comprehensive EDA on the Criteo CTR dataset.\n",
    "\n",
    "## Goals:\n",
    "- Understand data distribution\n",
    "- Analyze click rate\n",
    "- Examine feature distributions\n",
    "- Identify missing values\n",
    "- Explore correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from src.config import Config\n",
    "from src.utils.logging_utils import setup_logging\n",
    "from src.utils.spark_utils import create_spark_session\n",
    "from src.data.loader import CriteoDataLoader\n",
    "\n",
    "# Setup\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = Config('../config/config.yaml')\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(level='INFO')\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session(\n",
    "    app_name=config['spark']['app_name'],\n",
    "    master=config['spark']['master'],\n",
    "    executor_memory=config['spark']['executor_memory'],\n",
    "    driver_memory=config['spark']['driver_memory']\n",
    ")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "loader = CriteoDataLoader(spark, config)\n",
    "\n",
    "# Load sample data for EDA (use sample for faster analysis)\n",
    "sample_path = config['data']['sample_path']\n",
    "print(f\"Loading sample data from: {sample_path}\")\n",
    "\n",
    "# If sample doesn't exist, create it from raw data\n",
    "import os\n",
    "if not os.path.exists(sample_path) or len(os.listdir(sample_path)) == 0:\n",
    "    print(\"Sample not found. Loading raw data and creating sample...\")\n",
    "    raw_path = config['data']['raw_path']\n",
    "    df = loader.load_raw_data(raw_path)\n",
    "    df = loader.create_sample(df, config['data']['sample_size'], sample_path)\n",
    "else:\n",
    "    df = loader.load_parquet(sample_path)\n",
    "\n",
    "print(f\"Data loaded: {df.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "n_rows = df.count()\n",
    "n_cols = len(df.columns)\n",
    "\n",
    "print(f\"Dataset shape: {n_rows:,} rows × {n_cols} columns\")\n",
    "print(f\"\\nColumns: {df.columns}\")\n",
    "\n",
    "# Show schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample rows\n",
    "df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis (Click Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click distribution\n",
    "click_dist = df.groupBy('click').count().orderBy('click').toPandas()\n",
    "\n",
    "print(\"Click Distribution:\")\n",
    "print(click_dist)\n",
    "\n",
    "# Calculate percentages\n",
    "total = click_dist['count'].sum()\n",
    "click_dist['percentage'] = (click_dist['count'] / total * 100).round(2)\n",
    "\n",
    "print(\"\\nClick Distribution (with percentages):\")\n",
    "print(click_dist)\n",
    "\n",
    "# Calculate click rate\n",
    "click_rate = click_dist[click_dist['click'] == 1]['percentage'].values[0] / 100\n",
    "print(f\"\\nClick-Through Rate (CTR): {click_rate:.4f} ({click_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize click distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "axes[0].bar(click_dist['click'].astype(str), click_dist['count'], color=['blue', 'red'])\n",
    "axes[0].set_xlabel('Click')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Click Distribution (Count)')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['No Click (0)', 'Click (1)'])\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(\n",
    "    click_dist['count'],\n",
    "    labels=['No Click (0)', 'Click (1)'],\n",
    "    autopct='%1.2f%%',\n",
    "    colors=['blue', 'red']\n",
    ")\n",
    "axes[1].set_title('Click Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n⚠️ CLASS IMBALANCE: Only {click_rate*100:.2f}% of samples are clicks!\")\n",
    "print(\"This will require special handling (scale_pos_weight in XGBoost)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values for all columns\n",
    "missing_data = []\n",
    "\n",
    "for col in df.columns:\n",
    "    null_count = df.filter(F.col(col).isNull()).count()\n",
    "    null_pct = (null_count / n_rows) * 100\n",
    "    missing_data.append({\n",
    "        'column': col,\n",
    "        'missing_count': null_count,\n",
    "        'missing_percentage': null_pct\n",
    "    })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_data)\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values(\n",
    "    'missing_percentage', ascending=False\n",
    ")\n",
    "\n",
    "print(f\"Columns with missing values: {len(missing_df)} / {n_cols}\")\n",
    "print(\"\\nTop 10 columns with most missing values:\")\n",
    "print(missing_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(\n",
    "        range(len(missing_df.head(20))),\n",
    "        missing_df.head(20)['missing_percentage']\n",
    "    )\n",
    "    plt.yticks(\n",
    "        range(len(missing_df.head(20))),\n",
    "        missing_df.head(20)['column']\n",
    "    )\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.ylabel('Column')\n",
    "    plt.title('Top 20 Columns with Missing Values')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical columns\n",
    "numerical_cols = config['features']['numerical_cols']\n",
    "\n",
    "# Convert to Pandas for easier analysis (sample only)\n",
    "sample_size = min(100000, n_rows)\n",
    "df_sample = df.sample(False, sample_size / n_rows, seed=42).toPandas()\n",
    "\n",
    "print(f\"Analyzing {len(df_sample):,} sampled rows for numerical features...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Numerical Features Summary:\")\n",
    "print(df_sample[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for numerical features\n",
    "fig, axes = plt.subplots(5, 3, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    # Remove nulls for visualization\n",
    "    data = df_sample[col].dropna()\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        axes[idx].hist(data, bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'{col} Distribution')\n",
    "        axes[idx].set_xlabel('Value')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "        axes[idx].set_title(f'{col} Distribution (No Data)')\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical columns\n",
    "categorical_cols = config['features']['categorical_cols']\n",
    "\n",
    "# Analyze cardinality (number of unique values)\n",
    "cardinality_data = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df.select(col).distinct().count()\n",
    "    cardinality_data.append({\n",
    "        'column': col,\n",
    "        'unique_values': unique_count\n",
    "    })\n",
    "\n",
    "cardinality_df = pd.DataFrame(cardinality_data).sort_values(\n",
    "    'unique_values', ascending=False\n",
    ")\n",
    "\n",
    "print(\"Categorical Features Cardinality:\")\n",
    "print(cardinality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cardinality\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(cardinality_df)), cardinality_df['unique_values'])\n",
    "plt.yticks(range(len(cardinality_df)), cardinality_df['column'])\n",
    "plt.xlabel('Number of Unique Values')\n",
    "plt.ylabel('Column')\n",
    "plt.title('Categorical Features Cardinality')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis (Numerical Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_cols = ['click'] + numerical_cols\n",
    "correlation_matrix = df_sample[correlation_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=False,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title('Correlation Matrix (Numerical Features + Target)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with target\n",
    "print(\"\\nCorrelation with target (click):\")\n",
    "target_corr = correlation_matrix['click'].sort_values(ascending=False)\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EDA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Dataset Size: {n_rows:,} rows × {n_cols} columns\")\n",
    "print(f\"\\n2. Click-Through Rate: {click_rate:.4f} ({click_rate*100:.2f}%)\")\n",
    "print(f\"   - Class Imbalance: {(1-click_rate)*100:.2f}% No Click, {click_rate*100:.2f}% Click\")\n",
    "print(f\"   - Imbalance Ratio: {(1-click_rate)/click_rate:.1f}:1\")\n",
    "print(f\"\\n3. Missing Values: {len(missing_df)} columns have missing values\")\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"   - Highest missing: {missing_df.iloc[0]['column']} ({missing_df.iloc[0]['missing_percentage']:.2f}%)\")\n",
    "print(f\"\\n4. Numerical Features: {len(numerical_cols)} features (I1-I13)\")\n",
    "print(f\"\\n5. Categorical Features: {len(categorical_cols)} features (C1-C26)\")\n",
    "print(f\"   - Cardinality ranges from {cardinality_df['unique_values'].min():,} to {cardinality_df['unique_values'].max():,}\")\n",
    "print(f\"\\n6. Strongest correlations with target:\")\n",
    "top_corr = target_corr[target_corr.index != 'click'].head(3)\n",
    "for feat, corr_val in top_corr.items():\n",
    "    print(f\"   - {feat}: {corr_val:.4f}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"- Severe class imbalance requires special handling (scale_pos_weight)\")\n",
    "print(\"- Missing values need imputation\")\n",
    "print(\"- High cardinality categoricals need encoding (count/target encoding)\")\n",
    "print(\"- Weak correlations suggest non-linear relationships (good for tree models)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
