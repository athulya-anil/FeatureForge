{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download and Preparation - Criteo CTR Dataset\n",
    "\n",
    "This notebook helps you download and prepare the Criteo CTR dataset.\n",
    "\n",
    "## Dataset Information:\n",
    "- **Name**: Criteo Click-Through Rate Prediction\n",
    "- **Source**: Kaggle\n",
    "- **Size**: ~40M rows, ~10GB\n",
    "- **URL**: https://www.kaggle.com/c/criteo-display-ad-challenge\n",
    "\n",
    "## Steps:\n",
    "1. Download dataset from Kaggle\n",
    "2. Extract and place in `data/raw/`\n",
    "3. Create 1M row sample for testing\n",
    "4. Verify data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Manual Download (Recommended for First Time)\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Create Kaggle Account**:\n",
    "   - Go to https://www.kaggle.com/\n",
    "   - Sign up or log in\n",
    "\n",
    "2. **Get API Credentials**:\n",
    "   - Go to https://www.kaggle.com/settings/account\n",
    "   - Scroll to \"API\" section\n",
    "   - Click \"Create New API Token\"\n",
    "   - This downloads `kaggle.json` to your Downloads folder\n",
    "\n",
    "3. **Setup Kaggle API**:\n",
    "   ```bash\n",
    "   # Create .kaggle directory\n",
    "   mkdir -p ~/.kaggle\n",
    "   \n",
    "   # Move kaggle.json (replace path if different)\n",
    "   mv ~/Downloads/kaggle.json ~/.kaggle/\n",
    "   \n",
    "   # Set permissions\n",
    "   chmod 600 ~/.kaggle/kaggle.json\n",
    "   ```\n",
    "\n",
    "4. **Install Kaggle CLI**:\n",
    "   ```bash\n",
    "   pip install kaggle\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Download via Kaggle API (After Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install kaggle if not already installed\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Criteo dataset\n",
    "!kaggle competitions download -c criteo-display-ad-challenge -p ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = '../data/raw/criteo-display-ad-challenge.zip'\n",
    "extract_path = '../data/raw/'\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    print(f\"Extracting {zip_path}...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"Extraction complete!\")\n",
    "    \n",
    "    # List extracted files\n",
    "    print(\"\\nExtracted files:\")\n",
    "    for file in os.listdir(extract_path):\n",
    "        file_path = os.path.join(extract_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "            print(f\"  - {file} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"ZIP file not found: {zip_path}\")\n",
    "    print(\"Please download manually from Kaggle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Use Smaller Dataset for Testing\n",
    "\n",
    "If you don't have access to Kaggle or want to test quickly, you can generate synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.config import Config\n",
    "from src.utils.spark_utils import create_spark_session\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import random\n",
    "\n",
    "# Create config\n",
    "config = Config('../config/config.yaml')\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session(\n",
    "    app_name=\"SyntheticData\",\n",
    "    master=\"local[*]\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_synthetic_data(n_rows=10000):\n",
    "    \"\"\"Generate synthetic Criteo-like data for testing.\"\"\"\n",
    "    print(f\"Generating {n_rows:,} synthetic rows...\")\n",
    "    \n",
    "    data = []\n",
    "    for _ in range(n_rows):\n",
    "        row = [\n",
    "            random.choices([0, 1], weights=[0.97, 0.03])[0]  # click (3% CTR)\n",
    "        ]\n",
    "        \n",
    "        # Add numerical features I1-I13\n",
    "        for _ in range(13):\n",
    "            row.append(random.randint(0, 100) if random.random() > 0.1 else None)\n",
    "        \n",
    "        # Add categorical features C1-C26\n",
    "        for _ in range(26):\n",
    "            row.append(f\"cat_{random.randint(1, 1000)}\" if random.random() > 0.05 else None)\n",
    "        \n",
    "        data.append(tuple(row))\n",
    "    \n",
    "    # Define schema\n",
    "    fields = [StructField(\"click\", IntegerType(), True)]\n",
    "    for i in range(1, 14):\n",
    "        fields.append(StructField(f\"I{i}\", IntegerType(), True))\n",
    "    for i in range(1, 27):\n",
    "        fields.append(StructField(f\"C{i}\", StringType(), True))\n",
    "    \n",
    "    schema = StructType(fields)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = spark.createDataFrame(data, schema)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "synthetic_df = generate_synthetic_data(n_rows=10000)\n",
    "\n",
    "# Save as sample\n",
    "sample_path = '../data/sample/'\n",
    "synthetic_df.write.parquet(sample_path, mode='overwrite')\n",
    "\n",
    "print(f\"\\nSynthetic data saved to: {sample_path}\")\n",
    "print(f\"Rows: {synthetic_df.count():,}\")\n",
    "synthetic_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.config import Config\n",
    "from src.utils.spark_utils import create_spark_session\n",
    "from src.data.loader import CriteoDataLoader\n",
    "\n",
    "# Load config\n",
    "config = Config('../config/config.yaml')\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session(\n",
    "    app_name=config['spark']['app_name'],\n",
    "    master=config['spark']['master']\n",
    ")\n",
    "\n",
    "# Initialize loader\n",
    "loader = CriteoDataLoader(spark, config)\n",
    "\n",
    "# Try loading sample\n",
    "sample_path = config['data']['sample_path']\n",
    "df = loader.load_parquet(sample_path)\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Rows: {df.count():,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "df.show(5)\n",
    "\n",
    "# Check click rate\n",
    "from pyspark.sql import functions as F\n",
    "click_rate = df.filter(F.col('click') == 1).count() / df.count()\n",
    "print(f\"\\nClick rate: {click_rate:.4f} ({click_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark\n",
    "spark.stop()\n",
    "print(\"Spark session stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. ✅ Data downloaded and verified\n",
    "2. ➡️ Run `02_eda.ipynb` for exploratory data analysis\n",
    "3. ➡️ Run `03_baseline_model.ipynb` to train baseline model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
